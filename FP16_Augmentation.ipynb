{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FP16_Augmentation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTirqJzd5XFL5ux4J/jOW1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NNFLgroup31/Resnet50-Hyperparametertuning/blob/master/FP16_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLnart6EvvZ-",
        "colab_type": "text"
      },
      "source": [
        "## Import Packages And Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi1wF3f9CrQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import torchvision\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from torch.optim.lr_scheduler import LambdaLR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3FSLAZvwAz_",
        "colab_type": "text"
      },
      "source": [
        "##Input Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPJ5_b29wa5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=120\n",
        "bs=128\n",
        "lr=0.1\n",
        "model_save_name = 'Fp16_imagenet_Resnet-50.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmb4k35gwbTB",
        "colab_type": "text"
      },
      "source": [
        "## Model and Optimizer Intialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJxs7M0Awblv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        " model=torchvision.models.resnet50(pretrained=False) ##Resnet-50##\n",
        " #model=torchvision.models.mobilenet_v2(pretrained=False) ##Mobilenet_v2##\n",
        " return model,optim.SGD(model.parameters(),lr=lr,momentum=0.9,nesterov=True)\n",
        "model,opt=get_model()\n",
        "\n",
        "model.fc=nn.Linear(2048,10,bias=True) ##Resnet50##\n",
        "#model._modules['classifier']._modules['1']=nn.Linear(1280,10,bias=True) ##Mobilenet_v2##\n",
        "for layer in model.modules():\n",
        "  if isinstance(layer,nn.Conv2d):\n",
        "    torch.nn.init.xavier_uniform(layer.weight)\n",
        "  if isinstance(layer,nn.Linear):\n",
        "    torch.nn.init.xavier_uniform(layer.weight)\n",
        "  if isinstance(layer,nn.BatchNorm2d):\n",
        "    layer.weight.data.fill_(1)\n",
        "    layer.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-dDVnCC61dU",
        "colab_type": "text"
      },
      "source": [
        "##FP16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZsfqAnu63K1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.half()\n",
        "for layer in model.modules():\n",
        "  if isinstance(layer,nn.BatchNorm2d):\n",
        "    layer.float()\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud1Un515wbzC",
        "colab_type": "text"
      },
      "source": [
        "## Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXmS9dx7wb-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checkpoint={}\n",
        "history=[]\n",
        "#checkpoint=torch.load(path)\n",
        "epoch_last=1\n",
        "#model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#epoch_last=checkpoint['epoch']\n",
        "#history=checkpoint['history']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9ChOkzbwcHu",
        "colab_type": "text"
      },
      "source": [
        "## Scheduler "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqjNysQTwcT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def x(epoch):\n",
        "  if (epoch < 30):\n",
        "     return 1\n",
        "  elif (epoch >= 30) and (epoch<60):\n",
        "     return 0.1\n",
        "  elif  (epoch >= 60) and (epoch<90):\n",
        "     return 0.01\n",
        "  elif epoch >= 90:\n",
        "     return 0.001\n",
        "\n",
        "lambda1 = lambda epoch: x(epoch)\n",
        "scheduler = LambdaLR(opt, [lambda1])\n",
        "#scheduler.load_state_dict(checkpoint['scheduler'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIApJmJ7wce6",
        "colab_type": "text"
      },
      "source": [
        "## PCA Noise EigenValues,EigenVectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36tftQ-Vwcpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "__imagenet_pca = {\n",
        "    'eigval': torch.Tensor([0.2175, 0.0188, 0.0045]),\n",
        "    'eigvec': torch.Tensor([\n",
        "        [-0.5675,  0.7192,  0.4009],\n",
        "        [-0.5808, -0.0045, -0.8140],\n",
        "        [-0.5836, -0.6948,  0.4203],\n",
        "    ])\n",
        "}\n",
        "\n",
        "# PCA_Gaussian_noise\n",
        "class Lighting(object):\n",
        "    \n",
        "\n",
        "    def __init__(self, alphastd, eigval, eigvec):\n",
        "        self.alphastd = alphastd\n",
        "        self.eigval = eigval\n",
        "        self.eigvec = eigvec\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if self.alphastd == 0:\n",
        "            return img\n",
        "\n",
        "        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n",
        "        rgb = self.eigvec.type_as(img).clone()\\\n",
        "            .mul(alpha.view(1, 3).expand(3, 3))\\\n",
        "            .mul(self.eigval.view(1, 3).expand(3, 3))\\\n",
        "            .sum(1).squeeze()\n",
        "        return img.add(rgb.view(3, 1, 1).expand_as(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8wtv_kHwc6v",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy(Topk) & Loss Fuction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoJ14EwnwdFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "        res.append(correct_k)\n",
        "    return res\n",
        "\n",
        "loss_func=F.cross_entropy\n",
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "    loss = loss_func(model(xb), yb)\n",
        "    #print(loss)\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), len(xb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5jMz7CmwdQG",
        "colab_type": "text"
      },
      "source": [
        "## Mean & Standard Deviation of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxwmf-I-zUnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mean_and_std(train_dir):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataset = datasets.ImageFolder(train_dir,transforms.Compose([transforms.RandomResizedCrop(224),transforms.RandomHorizontalFlip(),torchvision.transforms.ColorJitter(brightness=(0.6,1.4),saturation=(0.6,1.4),hue=(-0.5,0.5)),transforms.ToTensor(), Lighting(0.1, __imagenet_pca['eigval'], __imagenet_pca['eigvec'])]))\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=1)\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    print('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:,i,:,:].mean()\n",
        "            std[i] += inputs[:,i,:,:].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHhVwdOhzVB_",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-PvonCPzVT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz ##Imagenette2##\n",
        "!tar -xvzf  'imagenette2.tgz'\n",
        "\n",
        "#!wget https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2.tgz ##Imagewoof2##\n",
        "#!tar -xvzf  'imagewoof2.tgz' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRhMrvhYzVqy",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing & DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btym4BAGzV0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir=os.path.join('/content/gdrive/My Drive/imagenette2/','train') #Imagenette2##\n",
        "val_dir=os.path.join('/content/gdrive/My Drive/imagenette2/','val')\n",
        "\n",
        "#train_dir=os.path.join('/content/imagewoof2','train') ##Imagewoof2##\n",
        "#val_dir=os.path.join('/content/imagewoof2','val')       \n",
        "\n",
        "mean_dataset,std_dataset=get_mean_and_std(train_dir)      \n",
        "normalize = transforms.Normalize(mean=mean_dataset,std=std_dataset)\n",
        "train_dataset = datasets.ImageFolder(train_dir,transforms.Compose([transforms.RandomResizedCrop(224),transforms.RandomHorizontalFlip(),torchvision.transforms.ColorJitter(brightness=(0.6,1.4),saturation=(0.6,1.4),hue=(-0.5,0.5)),transforms.ToTensor(), Lighting(0.1, __imagenet_pca['eigval'], __imagenet_pca['eigvec']),normalize]))\n",
        "train_loader=DataLoader(train_dataset,batch_size=bs,shuffle=True,pin_memory=True)\n",
        "val_loader=DataLoader(datasets.ImageFolder(val_dir,transforms.Compose([transforms.Resize(256),transforms.CenterCrop(224),transforms.ToTensor(),normalize])),batch_size=bs,shuffle=False,pin_memory=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WnOkLxG1rY4",
        "colab_type": "text"
      },
      "source": [
        "## Training & Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rutZo_hL1u7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epoch_last,epochs+1):\n",
        "        model.train()\n",
        "        t_loss=0\n",
        "        t_num=0\n",
        "        for xb, yb in train_loader:\n",
        "            xb=xb.to('cuda').half()\n",
        "            yb=yb.to('cuda')\n",
        "            a,b=loss_batch(model, loss_func, xb, yb, opt)\n",
        "            t_loss += a*b\n",
        "            t_num += b\n",
        "        train_loss=t_loss/t_num\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        losses=0\n",
        "        nums=0\n",
        "        correct1=0\n",
        "        correct2=0\n",
        "        correct3=0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "              xb=xb.to('cuda').half()\n",
        "              yb=yb.to('cuda')\n",
        "              l,c=loss_batch(model, loss_func, xb, yb)\n",
        "              losses +=l*c\n",
        "              nums += c\n",
        "              correct_class1,correct_class2,correct_class3 = accuracy(model(xb),yb,topk=(1,3,5))\n",
        "              correct1 += int(correct_class1)\n",
        "              correct2 += int(correct_class2)\n",
        "              correct3 += int(correct_class3)\n",
        "        val_loss = losses / nums\n",
        "        acc1=correct1/nums\n",
        "        acc2=correct2/nums\n",
        "        acc3=correct3/nums\n",
        "        history.append([epoch,train_loss,val_loss,acc1,acc2,acc3])\n",
        "        scheduler.step()\n",
        "        print(epoch,train_loss,val_loss,acc1,acc2,acc3)\n",
        "        torch.save({'epoch':epoch,'model_state_dict': model.state_dict(),'optimizer_state_dict': opt.state_dict(),'history':history,'scheduler':scheduler.state_dict()}, path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}